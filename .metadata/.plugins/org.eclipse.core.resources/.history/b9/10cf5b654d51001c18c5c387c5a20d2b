/*
 * generated by Xtext 2.25.0
 */
package org.xtext.example.perfectML.generator

import java.io.BufferedReader
import java.io.FileReader
import java.io.FileWriter
import java.util.ArrayList
import java.util.Arrays
import java.util.HashSet
import java.util.List
import java.util.Random
import java.util.Set
import org.eclipse.emf.ecore.resource.Resource
import org.eclipse.xtext.generator.AbstractGenerator
import org.eclipse.xtext.generator.IFileSystemAccess2
import org.eclipse.xtext.generator.IGeneratorContext
import org.xtext.example.perfectML.perfectML.ColumnDeclarations
import org.xtext.example.perfectML.perfectML.ColumnSet
import org.xtext.example.perfectML.perfectML.Input
import org.xtext.example.perfectML.perfectML.KNeighborsClassifier
import org.xtext.example.perfectML.perfectML.MLPClassifier
import org.xtext.example.perfectML.perfectML.Output
import org.xtext.example.perfectML.perfectML.PerfectMLFile
import org.xtext.example.perfectML.perfectML.Program
import org.xtext.example.perfectML.perfectML.SVC
import org.xtext.example.perfectML.perfectML.TrainingAmount

/**
 * Generates code from your model files on save.
 * 
 * See https://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html#code-generation
 */
class PerfectMLGenerator extends AbstractGenerator {

	override void doGenerate(Resource resource, IFileSystemAccess2 fsa, IGeneratorContext context) {
//		fsa.generateFile('greetings.txt', 'People to greet: ' + resource.allContents.toIterable().head.compile())
	}

	def dispatch String compile(PerfectMLFile file) {
		var res = '''
			import pandas as pd
			import numpy as np
		'''
		for (Program prog : file.programs) {
			res += prog.compile
		}
		res
	}

	def dispatch String compile(Program prog) {
		'''
			
			«prog.input.compile()»
			«prog.output.compile()»
			«prog.algo.compile()»
			«prog.nbtraining.compile()»
			pred_indexes = set([n for n in range(len(in_file)-1)])
			target_indexes = set([len(in_file) - 1])
			«IF prog.column !== null»
				«prog.column.compile()»
			«ENDIF»
			training_lines = in_file[:linesep]
			testing_lines = in_file[linesep:]
			
			training_data = training_lines[:, pred_indexes]
			
			training_targets = training_lines[:, target_indexes]
			
			test_data = testing_lines[:, pred_indexes]
			
			result = []
			
			for column in training_targets:
				clf.fit(training_data, column)
				result.append(clf.predict(test_data))
				
			
			# write result to a csv file
			pd.DataFrame.to_csv(out_file, result)
		'''

	}

	def dispatch String compile(Input input) {
		'''
			input_path = "«input.PATH»"
			in_file = pd.read_csv(input_path).to_numpy()
		'''
	}

	def dispatch String compile(Output output) {
		'''
			out_file = "«output.PATH»"
		'''
	}

	def dispatch String compile(SVC algoSVC) {
		'''
			from sklearn.svm import SVC
			clf = SVC()
			«algoSVC.compileParams()»
		'''
	}

	def dispatch String compile(MLPClassifier algoMLP) {
		'''
			from sklearn.neural_network import MLPClassifier
			clf = MLPClassifier()
			«algoMLP.compileParams()»
		'''
	}

	def dispatch String compile(KNeighborsClassifier algoKN) {
		'''
			from sklearn.neighbors import KNeighborsClassifier
			clf = KNeighborsClassifier()
			«algoKN.compileParams()»
		'''
	}

	def dispatch String compileParams(SVC algoSVC) {
		'''
			«IF algoSVC.c_def»
				clf.set_params(c=«algoSVC.c»)
			«ENDIF»
			«IF algoSVC.kernel_def»
				clf.set_params(kernel='«algoSVC.kernel»')
			«ENDIF»
			«IF algoSVC.degree_def»
				clf.set_params(degree=«algoSVC.degree»)
			«ENDIF»
			«IF algoSVC.gamma_def»
				clf.set_params(gamma='«algoSVC.gamma»')
			«ENDIF»
			«IF algoSVC.coef0_def»
				clf.set_params(coef0=«algoSVC.coef0»)
			«ENDIF»
			«IF algoSVC.shrinking_def»
				clf.set_params(shrinking=«algoSVC.shrinking»)
			«ENDIF»
			«IF algoSVC.probability_def»
				clf.set_params(probability=«algoSVC.probability»)
			«ENDIF»
			«IF algoSVC.tol_def»
				clf.set_params(tol=«algoSVC.tol»)
			«ENDIF»
			«IF algoSVC.cache_size_def»
				clf.set_params(cache_size=«algoSVC.cache_size»)
			«ENDIF»
			«IF algoSVC.verbose_def»
				clf.set_params(verbose=«algoSVC.verbose»)
			«ENDIF»
			«IF algoSVC.max_iter_def»
				clf.set_params(max_iter=«algoSVC.max_iter»
			«ENDIF»
			«IF algoSVC.decision_function_shape_def»
				clf.set_params(decision_function_shape='«algoSVC.decision_function_shape»')
			«ENDIF»
			«IF algoSVC.break_ties_def»
				clf.set_params(break_ties=«algoSVC.break_ties»)
			«ENDIF»
			«IF algoSVC.random_state_def»
				clf.set_params(random_state=«algoSVC.random_state»)
			«ENDIF»
		'''
	}

	def dispatch String compileParams(MLPClassifier algoMLP) {
		'''
			«IF algoMLP.hidden_layer_sizes_def»
				clf.set_params(hidden_layer_sizes=«algoMLP.hidden_layer_sizes»)
			«ENDIF»
			«IF algoMLP.activation_def»
				clf.set_params(activation=«algoMLP.activation»)
			«ENDIF»
			«IF algoMLP.solver_def»
				clf.set_params(solver=«algoMLP.solver»)
			«ENDIF»
			«IF algoMLP.alpha_def»
				clf.set_params(alpha=«algoMLP.alpha»)
			«ENDIF»
			«IF algoMLP.batch_size_def»
				clf.set_params(batch_size=«algoMLP.batch_size»)
			«ENDIF»
			«IF algoMLP.learning_rate_def»
				clf.set_params(learning_rate=«algoMLP.learning_rate»)
			«ENDIF»
			«IF algoMLP.learning_rate_init_def»
				clf.set_params(learning_rate_init=«algoMLP.learning_rate_init»)
			«ENDIF»
			«IF algoMLP.power_t_def»
				clf.set_params(power_t=«algoMLP.power_t»)
			«ENDIF»
			«IF algoMLP.max_iteer_def»
				clf.set_params(max_iter=«algoMLP.max_iter»)
			«ENDIF»
			«IF algoMLP.shuffle_def»
				clf.set_params(shuffle=«algoMLP.shuffle»)
			«ENDIF»
			«IF algoMLP.random_state_def»
				clf.set_params(random_state=«algoMLP.random_state»)
			«ENDIF»
			«IF algoMLP.tolerance_def»
				clf.set_params(tolerance=«algoMLP.tolerance»)
			«ENDIF»
			«IF algoMLP.verbose_def»
				clf.set_params(verbose=«algoMLP.verbose»)
			«ENDIF»
			«IF algoMLP.warm_start_def»
				clf.set_params(warm_start=«algoMLP.warm_start»)
			«ENDIF»
			«IF algoMLP.momentum_def»
				clf.set_params(momentum=«algoMLP.momentum»)
			«ENDIF»
			«IF algoMLP.nesterovs_momentum_def»
				clf.set_params(nesterovs_momentum=«algoMLP.nesterovs_momentum»)
			«ENDIF»
			«IF algoMLP.early_stopping_def»
				clf.set_params(early_stopping=«algoMLP.early_stopping»)
			«ENDIF»
			«IF algoMLP.validation_fraction_def»
				clf.set_params(validation_fraction=«algoMLP.validation_fraction»)
			«ENDIF»
			«IF algoMLP.beta_1_def»
				clf.set_params(beta_1=«algoMLP.beta_1»)
			«ENDIF»
			«IF algoMLP.beta_2_def»
				clf.set_params(beta_2=«algoMLP.beta_2»)
			«ENDIF»
			«IF algoMLP.epsilon_def»
				clf.set_params(epsilon=«algoMLP.epsilon»)
			«ENDIF»
			«IF algoMLP.n_iter_no_change_def»
				clf.set_params(n_iter_no_change=«algoMLP.n_iter_no_change»)
			«ENDIF»
			«IF algoMLP.max_fun_def»
				clf.set_params(max_fun=«algoMLP.max_fun»)
			«ENDIF»			
		'''
	}

	def dispatch String compileParams(KNeighborsClassifier algoKN) {
		'''
			«IF algoKN.n_neighbors_def»
				clf.set_params(n_neighbors=«algoKN.n_neighbors»)
			«ENDIF»
			«IF algoKN.weights_def»
				clf.set_params(weights='«algoKN.weights»')
			«ENDIF»
			«IF algoKN.algorithm_def»
				clf.set_params(algorithm='«algoKN.algorithm»')
			«ENDIF»
			«IF algoKN.leaf_size_def»
				clf.set_params(leaf_size=«algoKN.leaf_size»)
			«ENDIF»
			«IF algoKN.p_def»
				clf.set_params(p=«algoKN.p»)
			«ENDIF»
			«IF algoKN.metric_def»
				clf.set_params(metric='«algoKN.metric»')
			«ENDIF»
			«IF algoKN.n_jobs_def»
				clf.set_params(n_jobs=«algoKN.n_jobs»
			«ENDIF»
		'''
	}

	def dispatch String compile(TrainingAmount training) {
		'''
			«IF training.percent»
				linesep = («training.value» / 100) * len(in_file)
			«ELSE»
				linesep = «training.value»
			«ENDIF»
		'''
	}

	def dispatch String compile(ColumnDeclarations col) {
		'''
			
			target_indexes = «col.target.compile()»
			«IF col.pred_def»
				predictive_indexes = «col.predictive.compile()»
			«ENDIF»
			pred_indexes = pred_indexes.difference(target_indexes)
			pred_indexes = list(pred_indexes)
			target_indexes = list(target_indexes)
		'''
	}

	def dispatch String compile(ColumnSet colset) {
		if (colset.op) {
			'''
				«colset.argBin1.compile()»«IF colset.opType.type == "and"».union(«ELSE».difference(«ENDIF»«colset.argBin2.compile()»)
			'''
		} else if (colset.range) {
			'''
				set([n for n in range(«colset.argR1»,«colset.argR2»+1)])
			'''
		} else if (colset.list) {
			'''
				set([«colset.argList.join(' ')»])
			'''
		}
	}

	def void eval(PerfectMLFile file) {
		for (Program p : file.programs) {
			p.eval()
		}
	}

	def List<List<String>> eval(Program prog) {
		val in_file = prog.input.PATH
		val out_file = prog.output.PATH

		val isPercent = prog.nbtraining.percent

		val List<List<String>> data = new ArrayList()
		try (val BufferedReader br = new BufferedReader(new FileReader(in_file))) {
			var String line;
			while ((line = br.readLine()) !== null) {
				val String[] values = line.split(',');
				data.add(Arrays.asList(values))
			}
		} catch (Exception e) {
			System.out.println("Could not read from " + in_file)
			return new ArrayList()
		}
		var int linesep
		if (isPercent) {
			linesep = (prog.nbtraining.value / 100) * data.length
		} else {
			linesep = prog.nbtraining.value
		}

		val trainingLines = Arrays.copyOfRange(data, 0, linesep)
		val testingLines = Arrays.copyOfRange(data, linesep, data.length)

		val indexes = prog.column.eval(data.get(0).length)

		val pred_indexes = indexes.get(1)

		val training_targets = new ArrayList()
		for (Integer i : pred_indexes) {
			val resClass = new ArrayList()
			for (var j = 0; j < trainingLines.length; j++) {
				resClass.add(trainingLines.get(j).get(i))
			}
			training_targets.add(resClass)
		}
		
		val List<List<String>> result = new ArrayList()

		for (List<String> entry : testingLines) {
			val rand = new Random()
			val n = rand.nextInt(training_targets.size())
			result.add(training_targets.get(n))
		}

		// write result to out_file
		try (val FileWriter writer = new FileWriter(out_file)) {
			for (List<String> line : result) {
				writer.append(line.join(',') + "\n")
			}
		}
		return result
	}

	def Set<Integer>[] eval(ColumnDeclarations col, int size) {
		val targets = col.target.eval()
		var Set<Integer> pred
		if (col.pred_def) {
			pred = col.predictive.eval()
		} else {
			for (var i = 0; i < size - 1; i++) {
				pred.add(i)
			}
		}

		pred.removeAll(targets)
		return #[targets, pred]
	}

	def Set<Integer> eval(ColumnSet colset) {
		if (colset.op) {
			val result = colset.argBin1.eval()
			if (colset.opType.type == "and") {
				result.addAll(colset.argBin2.eval())
			} else {
				result.removeAll(colset.argBin2.eval())
			}
			result
		} else if (colset.range) {
			val result = new HashSet<Integer>()
			for (var i = colset.argR1; i <= colset.argR2; i++) {
				result.add(i)
			}
			result
		} else if (colset.list) {
			val result = new HashSet<Integer>()
			for (Integer i : colset.argList) {
				result.add(i)
			}
			result
		}

	}

}